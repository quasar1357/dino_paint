{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f9282643-c6fa-4806-8a91-0156710c8664",
   "metadata": {},
   "source": [
    "# Semantic Segmentation with convpaint and DINOv2\n",
    "\n",
    "This notebooks demonstrates how to run a semantic segmentation on an image using DINOv2 for feature extraction and a random forest algorithm for classification. It is based on the notebook provided by convpaint.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c9a1c36c",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e314538e-f42d-42d0-89a9-4ddd4588c483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import napari\n",
    "import numpy as np\n",
    "import skimage\n",
    "from matplotlib import pyplot as plt\n",
    "from dino_paint_utils import (train_dino_forest, predict_dino_forest)\n",
    "                              "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1570ce97",
   "metadata": {},
   "source": [
    "## Choose the model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6f82e4b3",
   "metadata": {},
   "source": [
    "Choose the DINOv2 model to be used:\n",
    "|key | model|\n",
    "|---|---|\n",
    "|'s' | dinov2_vits14|\n",
    "|'b' | dinov2_vitb14|\n",
    "|'l' | dinov2_vitl14|\n",
    "|'g' | dinov2_vitg14|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "80e4c999",
   "metadata": {},
   "outputs": [],
   "source": [
    "dinov2_model = 's'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "36382298",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3ea22d4c",
   "metadata": {},
   "source": [
    "Load an image and its annotation/labels to train the model on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7def2e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_original = skimage.data.cells3d()\n",
    "# image_original = image_original[30, 1]\n",
    "# from napari_convpaint.convpaint_sample import create_annotation_cell3d\n",
    "# labels_original = create_annotation_cell3d()[0][0]\n",
    "# crop = ((60,188), (0,128))\n",
    "# crop = ((20,20+224), (0,224))\n",
    "# image_original = image_original[crop[0][0]:crop[0][1], crop[1][0]:crop[1][1]]\n",
    "# labels_original = labels_original[crop[0][0]:crop[0][1], crop[1][0]:crop[1][1]]\n",
    "\n",
    "# LOAD ASTRONAUT IMAGE (RGB) AND ANNOTATION\n",
    "image_train = skimage.data.astronaut()#[0:504,0:504,:]\n",
    "labels_train = plt.imread('astro_labels_2.tif')[:,:,0]#[0:504,0:504]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "47e31289",
   "metadata": {},
   "source": [
    "Exctract the features using DINOv2 and use them to train a random forest classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bebe9781",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\roman/.cache\\torch\\hub\\facebookresearch_dinov2_main\n",
      "WARNING: QWindowsWindow::setGeometry: Unable to set geometry 3258x1965+957+270 (frame: 3290x2053+941+198) on QWidgetWindow/\"_QtMainWindowClassWindow\" on \"\\\\.\\DISPLAY1\". Resulting geometry: 5764x2108+965+311 (frame: 5796x2196+949+239) margins: 16, 72, 16, 16 minimum size: 385x494 MINMAXINFO maxSize=0,0 maxpos=0,0 mintrack=1187,1570 maxtrack=0,0)\n"
     ]
    }
   ],
   "source": [
    "random_forest, image_to_train, labels_to_train, features_space_train = train_dino_forest(image_train, labels_train, crop_to_patch=True, scale=1, dinov2_model=dinov2_model, show_napari=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "191fe950",
   "metadata": {},
   "source": [
    "Show the image and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2dee9d3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Labels layer 'labels_to_train' at 0x26893854fa0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# viewer = napari.Viewer()\n",
    "# viewer.add_image(image_to_train.astype(np.int32))\n",
    "# viewer.add_labels(labels_to_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d8625bc9",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8e01ea6d",
   "metadata": {},
   "source": [
    "Load an image to predict the labels for using the trained model above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "258e862b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_pred = skimage.data.camera()\n",
    "# image_pred = skimage.data.cat()\n",
    "image_pred = skimage.data.horse().astype(np.int32)\n",
    "# image_pred = skimage.data.binary_blobs().astype(np.int32)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9a2d834a",
   "metadata": {},
   "source": [
    "Exctract the features and use them together with the trained classifier to make a prediciton for the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8a7de01f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\roman/.cache\\torch\\hub\\facebookresearch_dinov2_main\n"
     ]
    }
   ],
   "source": [
    "predicted_labels, image_to_predict, features_space_predict = predict_dino_forest(image_pred, random_forest, crop_to_patch=True, scale=1, dinov2_model=dinov2_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "df49ac9c",
   "metadata": {},
   "source": [
    "Show the image and the predicted labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9af12dbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Labels layer 'predicted_labels' at 0x2694ea71a00>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# viewer = napari.Viewer()\n",
    "# viewer.add_image(image_to_predict.astype(np.int32))\n",
    "# viewer.add_labels(predicted_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
