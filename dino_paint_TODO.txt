
Why are accuracies lower than before correcting the rgb/annotation bug?!

Understand DINOv2; which model/layers (intermediate?) best for sem_seg? -> s. DINOv2 notebook


----------


Andere classifiers, bzw. z.B. leafs reduzieren beim random forest

(Interpolation in anderen beispielen --> s. links)

(Scikit resize uses a lot of resources/time; Hinweise Guillaume)

/ Why 646 annotated pixels from extract_annotated_pixels()?
/ --> postprocessing in extract_annotated_pixels verstehen und kontrollieren...

(Idee RS: gaussian smoothing zuerst?)


======================================

/ Docstrings...

======================================


// Rohes input image als feature mitgeben
// Mit vgg16 vergleichen und kombinieren...

// Wir trainen mit 14x14 features! Nicht nötig, oder gar schlecht ?!
// --> z.B. labels runter scalen statt features rauf? --> auch schneller
// ==> NEIN: Was, wenn unterschiedliche labels innerhalb patch?
// ==> Zudem, wenn kombinieren wollen mit anderen features, besser pixelwise

// Bessere Auflösung; z.B. scale input image, am schluss wieder runter scalen (wie wenn patch_sizes grösser/kleiner wären)

// --> image_scaled wird komisch; siehe Astro-Bild...

// Correctly normalized? --> see mean and sd afterwards (!= used ...)
// --> von Hand normalisieren und testen

// Correctly unlinearized?

// Normalization numbers correct? --> ok
// Pillow RGB ... --> ok

// Bigger Pic
// RGB input...

// Effect of Resize? --> why not working with those data types? --> works only on tensors or pil images